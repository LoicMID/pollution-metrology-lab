import streamlit as st
import pandas as pd
import numpy as np

# --- CONFIGURATION ---
st.set_page_config(
    page_title="Thesis Framework: Sensor Reliability",
    page_icon="üì°",
    layout="wide"
)

# --- HEADER ---
st.title("üì° Cadre M√©thodologique pour la Fiabilisation des Capteurs")
st.markdown("""
**Sujet de Th√®se :** *D√©veloppement d'un cadre m√©thodologique pour la fiabilisation de r√©seaux de capteurs 
de pollution de l'air : de la fiabilisation en laboratoire √† la maintenance dynamique in-situ.*
""")

# --- NAVIGATION ---
tab_context, tab_phase1, tab_phase2, tab_phase3 = st.tabs([
    "üè† Contexte & Enjeux", 
    "Phase 1 : M√©trologie", 
    "Phase 2 : Calibration IA", 
    "Phase 3 : Fusion de Donn√©es"
])

# ==================================================
# ONGLET 0 : CONTEXTE
# ==================================================
with tab_context:
    col1, col2 = st.columns([2, 1])
    with col1:
        st.header("Le D√©fi des Capteurs Low-Cost")
        st.write("""
        La pollution atmosph√©rique est un enjeu sanitaire majeur[cite: 3]. 
        Pour la surveiller, les capteurs low-cost offrent une couverture spatiale in√©dite[cite: 13, 14].
        
        Cependant, leur d√©ploiement massif est frein√© par trois limites techniques majeures :
        """)
        st.warning("1. Sensibilit√© aux facteurs environnementaux (T¬∞, Humidit√©) [cite: 18]")
        st.warning("2. D√©rive temporelle et vieillissement des composants [cite: 19]")
        st.warning("3. Faible s√©lectivit√© (incapacit√© √† discriminer certains polluants) [cite: 20]")
        
    with col2:
        st.info("üéØ Objectifs de la th√®se")
        st.markdown("""
        Ce projet vise √† d√©velopper un **cadre m√©thodologique complet** [cite: 44] pour :
        1.  **Qualifier** la fiabilit√© d'une donn√©e brute.
        2.  **Corriger** le signal via des algorithmes d'IA.
        3.  **Valider** la mesure via le contexte r√©seau.
        """)

# ==================================================
# PHASE 1 : METROLOGIE
# ==================================================
with tab_phase1:
    st.header("Phase 1 : Quantification de la Fiabilit√©")
    
    # --- LE "POURQUOI" (M√âTHODOLOGIE) ---
    with st.expander("üìò M√©thodologie : Comment d√©finit-on une mesure fiable ?"):
        st.markdown("""
        Avant de corriger, il faut mesurer l'erreur. Cette phase √©tablit un protocole rigoureux pour comparer 
        le capteur low-cost √† un instrument de r√©f√©rence[cite: 54, 56].
        
        Nous utilisons principalement deux m√©triques :
        * **La Justesse (Biais) :** L'√©cart moyen par rapport √† la r√©alit√©.
        * **L'Incertitude (Pr√©cision) :** La dispersion des mesures, souvent √©valu√©e par m√©thodes de Monte-Carlo ou bay√©siennes[cite: 30].
        """)
        st.latex(r'''
        RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{pred,i} - y_{ref,i})^2}
        ''')

    # --- LA D√âMO ---
    st.write("### üõ†Ô∏è Banc d'essai virtuel")
    
    # G√©n√©ration de donn√©es
    dates = pd.date_range("2024-01-01", periods=100, freq="h")
    ref = np.sin(np.linspace(0, 10, 100)) * 10 + 20
    sensor = ref * 0.8 + 5 + np.random.normal(0, 2, 100)
    df_p1 = pd.DataFrame({"Date": dates, "Reference": ref, "LowCost": sensor})
    
    col_metrics, col_plot = st.columns([1, 3])
    with col_metrics:
        bias = np.mean(df_p1["LowCost"] - df_p1["Reference"])
        rmse = np.sqrt(np.mean((df_p1["LowCost"] - df_p1["Reference"])**2))
        st.metric("Biais (Justesse)", f"{bias:.2f}")
        st.metric("RMSE (Incertitude)", f"{rmse:.2f}")
    with col_plot:
        st.line_chart(df_p1.set_index("Date"))

# ==================================================
# PHASE 2 : CALIBRATION IA
# ==================================================
with tab_phase2:
    st.header("Phase 2 : Algorithmes de Fiabilisation")

    # --- LE "COMMENT" (M√âTHODOLOGIE) ---
    with st.expander("üìò M√©thodologie : Pourquoi l'IA est-elle n√©cessaire ?"):
        st.markdown("""
        Les m√©thodes classiques (r√©gression lin√©aire) √©chouent car la relation entre le signal et la pollution 
        est **non-lin√©aire** et d√©pend des interf√©rences.
        
        **L'approche propos√©e :**
        Utiliser l'apprentissage automatique (R√©seaux de neurones, Random Forest) pour apprendre cette complexit√© 
        √† partir de donn√©es labellis√©es[cite: 23, 24].
        """)
        st.latex(r'''
        C_{est} = f(S_{raw}, T, RH, P)
        ''')
        st.caption("O√π f est une fonction non-lin√©aire apprise par le mod√®le.")

    # --- LA D√âMO ---
    st.info("Simulation interactive de la correction algorithmique.")
    gain = st.slider("Facteur de correction simul√©", 0.5, 1.5, 1.0)
    df_p1["Corrected"] = df_p1["LowCost"] * gain
    st.line_chart(df_p1.set_index("Date")[["Reference", "Corrected"]])

# ==================================================
# PHASE 3 : FUSION DE DONN√âES
# ==================================================
with tab_phase3:
    st.header("Phase 3 : Maintenance Dynamique & R√©seau")
    
    # --- LE "POURQUOI" (M√âTHODOLOGIE) ---
    with st.expander("üìò M√©thodologie : La force du r√©seau"):
        st.markdown("""
        Un capteur seul est vuln√©rable. En r√©seau, chaque capteur b√©n√©ficie du contexte de ses voisins.
        La m√©thodologie repose sur la **fusion de donn√©es h√©t√©rog√®nes** [cite: 33] pour :
        1.  Capturer les dynamiques spatio-temporelles de la pollution.
        2.  D√©tecter les anomalies (ex: un capteur d√©rive seul vs un pic de pollution global)[cite: 34].
        """)
    
    st.write("*Simulation de r√©seau √† venir...*")